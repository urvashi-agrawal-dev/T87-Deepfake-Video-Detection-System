{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2147c86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: pydrive in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gdown) (4.14.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gdown) (3.19.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gdown) (2.32.5)\n",
      "Requirement already satisfied: google-api-python-client>=1.2 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydrive) (2.186.0)\n",
      "Requirement already satisfied: oauth2client>=4.0.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydrive) (4.1.3)\n",
      "Requirement already satisfied: PyYAML>=3.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydrive) (6.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\shail\\appdata\\roaming\\python\\python313\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (6.32.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.2.6)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client>=1.2->pydrive) (0.31.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client>=1.2->pydrive) (2.42.1)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client>=1.2->pydrive) (0.2.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client>=1.2->pydrive) (2.28.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client>=1.2->pydrive) (4.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (1.71.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (1.26.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.2->pydrive) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.2->pydrive) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.2->pydrive) (4.9.1)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=1.2->pydrive) (3.2.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.2->pydrive) (0.6.1)\n",
      "Requirement already satisfied: rich in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4->gdown) (2.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shail\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\shail\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gdown pydrive tqdm tensorflow opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca621984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "import gdown\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dae33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_ID = '1Mu69hp0vWC_a1GqnP1u3LGLqrSfKRNoy'   \n",
    "OUTPUT_ZIP = 'Deepfake.zip'\n",
    "LOCAL_DATA_ROOT = './deepfake_dataset_local'\n",
    "UNZIP = True\n",
    "FRAMES_PER_VIDEO = 6\n",
    "FRAME_SIZE = (160, 160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64b89af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Downloading dataset from Google Drive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Mu69hp0vWC_a1GqnP1u3LGLqrSfKRNoy\n",
      "From (redirected): https://drive.google.com/uc?id=1Mu69hp0vWC_a1GqnP1u3LGLqrSfKRNoy&confirm=t&uuid=e22ad379-fe9c-4b0e-94e4-197cbeeded03\n",
      "To: c:\\Users\\shail\\Documents\\T87-Deepfake-Video-Detection-System\\Deepfake.zip\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.02G/4.02G [08:07<00:00, 8.25MB/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(OUTPUT_ZIP):\n",
    "    print(\"ğŸ“¥ Downloading dataset from Google Drive...\")\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={FILE_ID}\", OUTPUT_ZIP, quiet=False)\n",
    "else:\n",
    "    print(\"âœ… Dataset ZIP already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "604ffba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Extracting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 140003/140003 [02:29<00:00, 935.99it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Extraction complete: ./deepfake_dataset_local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if UNZIP:\n",
    "    print(\"ğŸ“¦ Extracting dataset...\")\n",
    "    os.makedirs(LOCAL_DATA_ROOT, exist_ok=True)\n",
    "    try:\n",
    "        with zipfile.ZipFile(OUTPUT_ZIP, 'r') as z:\n",
    "            for member in tqdm(z.namelist(), desc=\"Extracting\"):\n",
    "                try:\n",
    "                    z.extract(member, LOCAL_DATA_ROOT)\n",
    "                except Exception as e:\n",
    "                    print(\"Error extracting\", member, \":\", e)\n",
    "        print(\"âœ… Extraction complete:\", LOCAL_DATA_ROOT)\n",
    "    except Exception:\n",
    "        traceback.print_exc()\n",
    "        raise RuntimeError(\"Failed to unzip dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42ded56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected dataset root: ./deepfake_dataset_local\\real_vs_fake\\real-vs-fake\n",
      "real-vs-fake/ (files: 0)\n",
      "    test/ (files: 0)\n",
      "        fake/ (files: 10000)\n",
      "        real/ (files: 10000)\n",
      "    train/ (files: 0)\n",
      "        fake/ (files: 50000)\n",
      "        real/ (files: 50000)\n",
      "    valid/ (files: 0)\n",
      "        fake/ (files: 10000)\n",
      "        real/ (files: 10000)\n"
     ]
    }
   ],
   "source": [
    "def find_dataset_root(base):\n",
    "    for root, dirs, files in os.walk(base):\n",
    "        if {'train','valid','test'}.issubset(set(dirs)):\n",
    "            return root\n",
    "        if {'real','fake'}.issubset(set(dirs)):\n",
    "            return root\n",
    "    return None\n",
    "\n",
    "DATA_ROOT = find_dataset_root(LOCAL_DATA_ROOT)\n",
    "if DATA_ROOT is None:\n",
    "    print(\"Could not auto-detect dataset root. Inspect:\", LOCAL_DATA_ROOT)\n",
    "    print(\"Contents:\", os.listdir(LOCAL_DATA_ROOT))\n",
    "else:\n",
    "    print(\"Detected dataset root:\", DATA_ROOT)\n",
    "    \n",
    "for root, dirs, files in os.walk(DATA_ROOT):\n",
    "    depth = root.replace(DATA_ROOT, '').count(os.sep)\n",
    "    indent = ' ' * 4 * depth\n",
    "    print(f\"{indent}{os.path.basename(root)}/ (files: {len(files)})\")\n",
    "    if depth >= 2:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fe9c0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/valid/test already exist. Skipping split.\n",
      "Final ROOT: ./deepfake_dataset_local\\real_vs_fake\\real-vs-fake\n",
      "train/real â†’ 50000 files\n",
      "train/fake â†’ 50000 files\n",
      "valid/real â†’ 10000 files\n",
      "valid/fake â†’ 10000 files\n",
      "test/real â†’ 10000 files\n",
      "test/fake â†’ 10000 files\n"
     ]
    }
   ],
   "source": [
    "def ensure_splits(root, ratio=(0.8, 0.1, 0.1)):\n",
    "    splits = ['train','valid','test']\n",
    "    classes = []\n",
    "\n",
    "    if os.path.exists(os.path.join(root, 'train')):\n",
    "        print(\"train/valid/test already exist. Skipping split.\")\n",
    "        return root\n",
    "\n",
    "    for cls in ['real','fake']:\n",
    "        if os.path.exists(os.path.join(root, cls)):\n",
    "            classes.append(cls)\n",
    "\n",
    "    if not classes:\n",
    "        raise RuntimeError(\"No 'real'/'fake' folders found.\")\n",
    "\n",
    "    for cls in classes:\n",
    "        cls_path = os.path.join(root, cls)\n",
    "        items = [f for f in os.listdir(cls_path) if not f.startswith('.')]\n",
    "        random.shuffle(items)\n",
    "        n = len(items)\n",
    "        n_train = int(ratio[0]*n)\n",
    "        n_valid = int(ratio[1]*n)\n",
    "\n",
    "        for split in splits:\n",
    "            os.makedirs(os.path.join(root, split, cls), exist_ok=True)\n",
    "\n",
    "        for i, f in enumerate(items):\n",
    "            src = os.path.join(cls_path, f)\n",
    "            if i < n_train:\n",
    "                dst = os.path.join(root, 'train', cls, f)\n",
    "            elif i < n_train + n_valid:\n",
    "                dst = os.path.join(root, 'valid', cls, f)\n",
    "            else:\n",
    "                dst = os.path.join(root, 'test', cls, f)\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "        try: os.rmdir(cls_path)\n",
    "        except OSError: pass\n",
    "\n",
    "    print(\"âœ… Created train/valid/test splits.\")\n",
    "    return root\n",
    "\n",
    "ROOT = ensure_splits(DATA_ROOT)\n",
    "print(\"Final ROOT:\", ROOT)\n",
    "\n",
    "# Verify\n",
    "for split in ['train','valid','test']:\n",
    "    for cls in ['real','fake']:\n",
    "        p = os.path.join(ROOT, split, cls)\n",
    "        print(f\"{split}/{cls} â†’ {len(os.listdir(p)) if os.path.exists(p) else 0} files\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6f5c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train/real: 50000 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train/real: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [03:42<00:00, 224.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train/fake: 50000 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train/fake: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [04:19<00:00, 192.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing valid/real: 10000 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid/real: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:47<00:00, 209.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing valid/fake: 10000 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid/fake: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:47<00:00, 210.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test/real: 10000 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test/real: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:49<00:00, 202.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test/fake: 10000 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test/fake: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:47<00:00, 212.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame extraction complete â†’ ./frames_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "OUT_FRAMES_DIR = './frames_dataset'\n",
    "os.makedirs(OUT_FRAMES_DIR, exist_ok=True)\n",
    "\n",
    "def extract_frames_from_video(video_path, out_dir, n_frames=FRAMES_PER_VIDEO, resize=FRAME_SIZE):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total <= 0:\n",
    "        cap.release()\n",
    "        return 0\n",
    "    indices = list(map(int, np.linspace(0, max(total-1,0), n_frames)))\n",
    "    saved = 0\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        frame = cv2.resize(frame, resize)\n",
    "        cv2.imwrite(os.path.join(out_dir, f'frame_{saved:03d}.jpg'), frame)\n",
    "        saved += 1\n",
    "    cap.release()\n",
    "    return saved\n",
    "\n",
    "for split in ['train','valid','test']:\n",
    "    for cls in ['real','fake']:\n",
    "        in_dir = os.path.join(ROOT, split, cls)\n",
    "        out_split_cls = os.path.join(OUT_FRAMES_DIR, split, cls)\n",
    "        os.makedirs(out_split_cls, exist_ok=True)\n",
    "        videos = [f for f in os.listdir(in_dir) if os.path.isfile(os.path.join(in_dir, f))]\n",
    "        print(f\"Processing {split}/{cls}: {len(videos)} videos\")\n",
    "        for v in tqdm(videos, desc=f\"{split}/{cls}\"):\n",
    "            vname = os.path.splitext(v)[0]\n",
    "            out_folder = os.path.join(out_split_cls, vname)\n",
    "            if os.path.exists(out_folder): continue\n",
    "            try:\n",
    "                extract_frames_from_video(os.path.join(in_dir, v), out_folder)\n",
    "            except Exception as e:\n",
    "                print(\"Error:\", v, e)\n",
    "\n",
    "print(\"Frame extraction complete â†’\", OUT_FRAMES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f46a7d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 100000 valid: 20000 test: 20000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "\n",
    "class VideoSequence(tf.keras.utils.Sequence):\n",
    "    def __init__(self, list_dirs, batch_size=4, frames=FRAMES_PER_VIDEO, shuffle=True):\n",
    "        self.list_dirs = list_dirs\n",
    "        self.batch_size = batch_size\n",
    "        self.frames = frames\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.list_dirs))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.list_dirs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_idxs = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        dirs = [self.list_dirs[i] for i in batch_idxs]\n",
    "        X = np.zeros((len(dirs), self.frames, FRAME_SIZE[0], FRAME_SIZE[1], 3), dtype=np.float32)\n",
    "        y = np.zeros((len(dirs),), dtype=np.int32)\n",
    "\n",
    "        for i, d in enumerate(dirs):\n",
    "            frames_files = sorted(glob.glob(os.path.join(d, '*.jpg')))\n",
    "            if len(frames_files) < self.frames:\n",
    "                frames_files = frames_files + [frames_files[-1]]*(self.frames - len(frames_files))\n",
    "            frames_files = frames_files[:self.frames]\n",
    "            arrs = []\n",
    "            for f in frames_files:\n",
    "                img = tf.keras.preprocessing.image.load_img(f, target_size=FRAME_SIZE)\n",
    "                ar = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                ar = preprocess_input(ar)\n",
    "                arrs.append(ar)\n",
    "            X[i] = np.stack(arrs)\n",
    "            y[i] = 0 if '/real/' in d else 1\n",
    "        return X, tf.keras.utils.to_categorical(y, num_classes=2)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "def collect_dirs(frames_root, split):\n",
    "    out = []\n",
    "    for cls in ['real','fake']:\n",
    "        base = os.path.join(frames_root, split, cls)\n",
    "        if not os.path.exists(base): continue\n",
    "        for v in os.listdir(base):\n",
    "            if os.path.isdir(os.path.join(base, v)):\n",
    "                out.append(os.path.join(base, v))\n",
    "    return out\n",
    "\n",
    "train_dirs = collect_dirs(OUT_FRAMES_DIR, 'train')\n",
    "valid_dirs = collect_dirs(OUT_FRAMES_DIR, 'valid')\n",
    "test_dirs = collect_dirs(OUT_FRAMES_DIR, 'test')\n",
    "\n",
    "print(\"train:\", len(train_dirs), \"valid:\", len(valid_dirs), \"test:\", len(test_dirs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bdf596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fast_xception_model(frames=FRAMES_PER_VIDEO):\n",
    "    base = Xception(weights='imagenet', include_top=False, pooling='avg', input_shape=(FRAME_SIZE[0], FRAME_SIZE[1], 3))\n",
    "    base.trainable = False\n",
    "    inp = layers.Input(shape=(frames, FRAME_SIZE[0], FRAME_SIZE[1], 3))\n",
    "    x = layers.TimeDistributed(base)(inp)\n",
    "    x = layers.Conv1D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(2, activation='softmax')(x)\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    return model\n",
    "\n",
    "model = build_fast_xception_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faab7e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ time_distributed_1              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,280</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling1d_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m3\u001b[0m) â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ time_distributed_1              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        â”‚    \u001b[38;5;34m20,861,480\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mTimeDistributed\u001b[0m)               â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚       \u001b[38;5;34m393,280\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling1d_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              â”‚           \u001b[38;5;34m130\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,259,050</span> (81.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,259,050\u001b[0m (81.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">397,570</span> (1.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m397,570\u001b[0m (1.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> (79.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,861,480\u001b[0m (79.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
